{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Prediction - regression and classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line:\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "allows you to display charts without using plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "This method assumes that the relationship between the explained and the explanatory variable is linear, i.e. we are trying to find the function:\n",
    "\n",
    "y = a * x + b\n",
    "\n",
    "that best describes the points from the set, where:\n",
    "\n",
    "- y - explained variable,\n",
    "- x - explanatory variable,\n",
    "- a - slope coefficient,\n",
    "- b - intercept."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the regression example, we will use generated points randomly spaced from the line with slope coefficient a = 2 and intercept b = -3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(1)\n",
    "x = 10 * rng.rand(50)\n",
    "y = 2 * x - 3 + rng.randn(50)\n",
    "plt.scatter(x, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the model for linear regression from the scikit-learn package (sklearn) and create the appropriate object. When creating an object, we can set values for the model's hyperparameters. One of such parameters is *fit_intercept*, which indicates whether the model should determine the value for the intercept **b**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression(fit_intercept=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The explanatory data should have dimension $<$number of samples$>$ x $<$number of dimensions/features$>$, so we need to change the dimensions for **x**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x[:, np.newaxis]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the model on the data. We can view the determined values for model parameters **a** and **b**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y)\n",
    "# a\n",
    "model.coef_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b\n",
    "model.intercept_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the designated linear regression model to \"new\" data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xfit = np.linspace(0, 10, 1000)\n",
    "yfit = model.predict(xfit[:, np.newaxis])\n",
    "\n",
    "# Visualization of results\n",
    "plt.scatter(x, y)\n",
    "plt.plot(xfit, yfit,'-r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Task 1. (0.5 points)\n",
    "> Using a phone company's data and a linear regression model, determine an exact per-minute rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We are looking for the relationship between body weight and brain weight for mammals in the form of a function:\n",
    "\n",
    "y = a * x,\n",
    "\n",
    "where *x* means brain weight and *y* means body weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the appropriate file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('brain_body.csv', index_col='Index')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2. (0.5 points)\n",
    "> Investigate whether there is a correlation between the variables under study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3. (0.5 points)\n",
    "> Create a linear regression model object suitable for the dependencies in the above problem.\n",
    ">\n",
    "> Prepare the explanatory variable (name it *X*) and the explained variable (name it *y*) appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We divide the dataset into test and training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X1, X2, y1, y2 = train_test_split(X, y, random_state=0,\n",
    "                                  train_size=0.6)\n",
    "print ('Size of training set = %d and test set = %d' % (y1.size, y2.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train and evaluate the model using mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model.fit(X1, y1)\n",
    "y2_model = model.predict(X2)\n",
    "\n",
    "mean_squared_error(y2, y2_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X2, y2)\n",
    "plt.plot(X2, y2_model,'-r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4. (1.5 points)\n",
    "> Remove outlying points from the analyzed data set and repeat the regression. Compare the results. Also compare the accuracy of the model on training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the process consists of several stages, the *Pipeline* class can be used.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "\n",
    "The following example defines a process consisting of data transformation (*PolynomialFeatures*) and linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly_model = make_pipeline(PolynomialFeatures(7),\n",
    "                           LinearRegression())\n",
    "\n",
    "rng = np.random.RandomState(1)\n",
    "x = 10 * rng.rand(50)\n",
    "y = np.sin(x) + 0.1 * rng.randn(50)\n",
    "\n",
    "poly_model.fit(x[:, np.newaxis], y)\n",
    "yfit = poly_model.predict(xfit[:, np.newaxis])\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.plot(xfit, yfit);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5. (0.5 points)\n",
    "> Test other values (smaller and larger than the example) as an argument when creating an object of the *PolynomialFeatures* class. What can you say about the model's behavior?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6. (1.5 points)\n",
    "> For the above random data, test the regression with $L_2$ regularization and $L_1$ regularization. Draw a graph and calculate the mean squared and mean absolute errors for the three models. Compare the results.\n",
    ">\n",
    "> **NOTE:** Both model error measures are available in the *sklearn.metrics* module.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here...\n",
    "from sklearn.linear_model import Ridge # L2\n",
    "from sklearn.linear_model import Lasso # L1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Linear regression as a function of two variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"boston_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(df.iloc[:,:-1])\n",
    "y = pd.DataFrame(df.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, X2, y1, y2 = train_test_split(X, y, random_state=0,\n",
    "                                  train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X1[['RM', 'LSTAT']].values.reshape(-1,2)\n",
    "x_test = X2[['RM', 'LSTAT']].values.reshape(-1,2)\n",
    "model = LinearRegression(fit_intercept=False)\n",
    "model.fit(x_train,y1)\n",
    "y2_model = model.predict(x_test)\n",
    "mean_squared_error(y2, y2_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7. (2.5 points)\n",
    "> Load the *winequality-red.csv* file and divide it into training and testing sets in the ratio of 7:3. Research the correlation between available attributes and wine quality and select several (min. 2) to create a model. If necessary, use a polynomial model. Use the $L_2$ regularization and examine the mean squared and absolute mean errors as well as the coefficient of determination. Compare the results.\n",
    ">\n",
    "> **NOTE:** The coefficient of determination is available in the sklearn.metrics module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1,2],\n",
    "             [5,8],\n",
    "             [1.5,1.8],\n",
    "             [8,8],\n",
    "             [1,0.6],\n",
    "             [9,11]])\n",
    "y = [0,1,0,1,0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create and teach a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel = 'linear')\n",
    "clf.fit(X, y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification of the new point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict([[0.58,0.76]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict([[10.58,10.76]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = clf.coef_[0]\n",
    "print(w)\n",
    "\n",
    "a = -w[0] / w[1]\n",
    "\n",
    "xx = np.linspace(0,12)\n",
    "yy = a * xx - clf.intercept_[0] / w[1]\n",
    "\n",
    "h0 = plt.plot(xx, yy, '-r')\n",
    "plt.scatter(X[:, 0], X[:, 1], c = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting support vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.support_vectors_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting vectors indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.support_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the number of support vectors for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.n_support_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8. (2.5 points)\n",
    "> Perform classification using the SVM method on the *iris* dataset. Divide the data into training and test data in a 4:1 ratio. Test different values for *kernel* ('linear','rbf','poly','sigmoid') and *gamma* (0, 10, 100) for *kernel*='rbf'. Compare accuracy on training and test sets for different model parameters. Also check the *f1* values for the prediction results of the tested models.\n",
    ">\n",
    "> **NOTE:** The *f1* measure is available in the *sklearn.metrics* module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import of the *iris* dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2] \n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
