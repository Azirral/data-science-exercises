{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-14T12:21:51.074794Z",
     "start_time": "2024-11-14T12:21:50.407044Z"
    }
   },
   "source": [
    "from surprise import Dataset\n",
    "from surprise.prediction_algorithms import knns\n",
    "from surprise.model_selection import cross_validate, train_test_split, GridSearchCV"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T20:32:15.303227Z",
     "start_time": "2024-11-14T12:27:06.578445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise import KNNBasic, KNNBaseline, KNNWithMeans, KNNWithZScore\n",
    "from surprise.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "\n",
    "# Loading the movielens-100k\n",
    "data = Dataset.load_builtin(\"ml-100k\")\n",
    "\n",
    "# test set is made of 30% of the ratings\n",
    "trainset, testset = train_test_split(data, test_size=0.30)\n",
    "\n",
    "# Define the algorithms to test\n",
    "algos = [\n",
    "    KNNBasic,  # Note: removed parentheses - we pass the class, not instance\n",
    "    KNNBaseline,\n",
    "    KNNWithMeans,\n",
    "    KNNWithZScore\n",
    "]\n",
    "\n",
    "# Define parameters for each algorithm\n",
    "param_grids = defaultdict(dict)\n",
    "\n",
    "# Basic parameters for all algorithms\n",
    "base_params = {\n",
    "    'k': [10, 20, 50, 100],\n",
    "    'min_k': [2, 4, 6, 8],\n",
    "    'sim_options': {\n",
    "        'name': ['cosine', 'msd', 'pearson', 'pearson_baseline'],\n",
    "        'min_support': [1, 5],\n",
    "        'user_based': [True, False]\n",
    "    },\n",
    "    'verbose': [False]\n",
    "}\n",
    "\n",
    "# Add base params to all algorithms\n",
    "for algo in algos:\n",
    "    param_grids[algo] = dict(base_params)\n",
    "\n",
    "# Add specific params for KNNBaseline\n",
    "param_grids[KNNBaseline].update({\n",
    "    'bsl_options': {\n",
    "        'method': ['als', 'sgd'],\n",
    "        'reg': [1, 2]\n",
    "    }\n",
    "})\n",
    "\n",
    "results = []\n",
    "\n",
    "# Performing Grid Search for best estimator\n",
    "for algo in algos:\n",
    "    print(f\"\\nRunning grid search for {algo.__name__}\")\n",
    "\n",
    "    gs = GridSearchCV(algo,\n",
    "                      param_grids[algo],\n",
    "                      measures=['rmse', 'mae'],\n",
    "                      cv=5)\n",
    "\n",
    "    gs.fit(data)\n",
    "\n",
    "    # Get best RMSE and MAE scores\n",
    "    best_rmse = gs.best_score['rmse']\n",
    "    best_mae = gs.best_score['mae']\n",
    "\n",
    "    # Get best parameters\n",
    "    best_params = gs.best_params['rmse']  # using RMSE params\n",
    "\n",
    "    results.append({\n",
    "        'algorithm': algo.__name__,\n",
    "        'best_rmse': best_rmse,\n",
    "        'best_mae': best_mae,\n",
    "        'best_params': best_params\n",
    "    })\n",
    "\n",
    "    print(f\"Best RMSE: {best_rmse}\")\n",
    "    print(f\"Best MAE: {best_mae}\")\n",
    "    print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "# Print final summary\n",
    "print(\"\\nFinal Summary:\")\n",
    "for result in results:\n",
    "    print(f\"\\nAlgorithm: {result['algorithm']}\")\n",
    "    print(f\"Best RMSE: {result['best_rmse']:.4f}\")\n",
    "    print(f\"Best MAE: {result['best_mae']:.4f}\")"
   ],
   "id": "77ebae070880a0de",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running grid search for KNNBasic\n",
      "Best RMSE: 0.9716130125245481\n",
      "Best MAE: 0.7659787197420254\n",
      "Best parameters: {'k': 20, 'min_k': 2, 'sim_options': {'name': 'msd', 'min_support': 5, 'user_based': True}, 'verbose': False}\n",
      "\n",
      "Running grid search for KNNBaseline\n",
      "Best RMSE: 0.9146800892000091\n",
      "Best MAE: 0.7185465589848159\n",
      "Best parameters: {'k': 50, 'min_k': 8, 'sim_options': {'name': 'pearson_baseline', 'min_support': 1, 'user_based': False}, 'verbose': False, 'bsl_options': {'method': 'als', 'reg': 1}}\n",
      "\n",
      "Running grid search for KNNWithMeans\n",
      "Best RMSE: 0.9215293349039587\n",
      "Best MAE: 0.7204320399171453\n",
      "Best parameters: {'k': 50, 'min_k': 4, 'sim_options': {'name': 'pearson_baseline', 'min_support': 1, 'user_based': False}, 'verbose': False}\n",
      "\n",
      "Running grid search for KNNWithZScore\n",
      "Best RMSE: 0.9231723365795714\n",
      "Best MAE: 0.7216026031774573\n",
      "Best parameters: {'k': 50, 'min_k': 4, 'sim_options': {'name': 'pearson_baseline', 'min_support': 1, 'user_based': False}, 'verbose': False}\n",
      "\n",
      "Final Summary:\n",
      "\n",
      "Algorithm: KNNBasic\n",
      "Best RMSE: 0.9716\n",
      "Best MAE: 0.7660\n",
      "\n",
      "Algorithm: KNNBaseline\n",
      "Best RMSE: 0.9147\n",
      "Best MAE: 0.7185\n",
      "\n",
      "Algorithm: KNNWithMeans\n",
      "Best RMSE: 0.9215\n",
      "Best MAE: 0.7204\n",
      "\n",
      "Algorithm: KNNWithZScore\n",
      "Best RMSE: 0.9232\n",
      "Best MAE: 0.7216\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T09:39:47.916041Z",
     "start_time": "2024-11-19T09:39:47.155163Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from surprise import AlgoBase\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "class ItemAveragePredictor(AlgoBase):\n",
    "    def __init__(self):\n",
    "        AlgoBase.__init__(self)\n",
    "        self.item_means = {}\n",
    "\n",
    "    def fit(self, trainset):\n",
    "        AlgoBase.fit(self, trainset)\n",
    "\n",
    "        # Calculate mean rating for each item\n",
    "        item_ratings = defaultdict(list)\n",
    "        for uid, iid, rating in trainset.all_ratings():\n",
    "            item_ratings[iid].append(rating)\n",
    "\n",
    "        # Calculate and store mean for each item\n",
    "        for iid in item_ratings:\n",
    "            self.item_means[iid] = np.mean(item_ratings[iid])\n",
    "\n",
    "        # Calculate global mean for items without ratings\n",
    "        self.global_mean = trainset.global_mean\n",
    "\n",
    "        return self\n",
    "\n",
    "    def estimate(self, u, i):\n",
    "        # If item has no ratings, return global mean\n",
    "        return self.item_means.get(i, self.global_mean)\n",
    "\n",
    "# Load the same dataset\n",
    "data = Dataset.load_builtin(\"ml-100k\")\n",
    "trainset, testset = train_test_split(data, test_size=0.30)\n",
    "\n",
    "# Train and evaluate the naive predictor\n",
    "naive_algo = ItemAveragePredictor()\n",
    "naive_algo.fit(trainset)\n",
    "predictions = naive_algo.test(testset)\n",
    "\n",
    "# Calculate RMSE and MAE\n",
    "naive_rmse = accuracy.rmse(predictions)\n",
    "naive_mae = accuracy.mae(predictions)\n",
    "\n",
    "print(\"\\nNaive Item Average Predictor Results:\")\n",
    "print(f\"RMSE: {naive_rmse:.4f}\")\n",
    "print(f\"MAE: {naive_mae:.4f}\")"
   ],
   "id": "3b40b94b8528eab1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0225\n",
      "MAE:  0.8167\n",
      "\n",
      "Naive Item Average Predictor Results:\n",
      "RMSE: 1.0225\n",
      "MAE: 0.8167\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **Comparison of Algorithm Performance**\n",
    "\n",
    "#### **1. Naive Item Average Predictor**\n",
    "- **RMSE**: 1.0225  \n",
    "- **MAE**: 0.8167  \n",
    "The Naive Item Average Predictor computes predictions by averaging item ratings, which results in the highest error rates among all the tested algorithms. Its simplicity and lack of personalization make it less effective for capturing user-item preferences.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. KNN Algorithms**\n",
    "**a. KNNBasic**  \n",
    "- **Best RMSE**: 0.9716  \n",
    "- **Best MAE**: 0.7660  \n",
    "KNNBasic, which uses a simple k-nearest neighbors approach, demonstrates a significant improvement over the Naive Item Average Predictor. It provides a better understanding of user or item similarity but does not incorporate advanced baseline adjustments.\n",
    "\n",
    "**b. KNNBaseline**  \n",
    "- **Best RMSE**: 0.9147  \n",
    "- **Best MAE**: 0.7185  \n",
    "KNNBaseline achieves the best performance among the tested algorithms. By incorporating baseline estimates (e.g., average ratings adjusted for biases), it effectively reduces prediction errors, particularly in RMSE and MAE.\n",
    "\n",
    "**c. KNNWithMeans**  \n",
    "- **Best RMSE**: 0.9215  \n",
    "- **Best MAE**: 0.7204  \n",
    "KNNWithMeans improves upon KNNBasic by considering the mean ratings of users or items. While slightly less accurate than KNNBaseline, it still outperforms the Naive Predictor.\n",
    "\n",
    "**d. KNNWithZScore**  \n",
    "- **Best RMSE**: 0.9232  \n",
    "- **Best MAE**: 0.7216  \n",
    "KNNWithZScore introduces Z-score normalization, but its performance is comparable to KNNWithMeans and slightly less accurate than KNNBaseline.\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary**\n",
    "- **KNNBaseline** is the top-performing algorithm, achieving the lowest RMSE (0.9147) and MAE (0.7185). Its use of baseline adjustments and sophisticated similarity metrics proves highly effective.\n",
    "- The Naive Item Average Predictor has the highest error rates, highlighting the need for personalized algorithms in recommendation systems.\n",
    "- Among the KNN-based models, KNNBasic provides a good baseline, while KNNBaseline's enhancements make it the best overall choice for minimizing prediction errors.\n"
   ],
   "id": "5271d4d3898f3e7d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
